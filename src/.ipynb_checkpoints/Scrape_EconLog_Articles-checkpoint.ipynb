{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45099f",
   "metadata": {
    "cell_id": "00000-6a4f05b3-350c-489d-aad2-a8a9477366f0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1626196754921,
    "source_hash": "10129497"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5510be",
   "metadata": {
    "cell_id": "00002-875c712e-10c9-40b7-b9b0-8edee8c61ef0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Create Functions for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169648fc",
   "metadata": {
    "cell_id": "00001-04ad014f-2a33-4631-a852-71b506db1142",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1626196754973,
    "source_hash": "861bae88",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_request(url, params=None):\n",
    "    \"\"\"\n",
    "    Performs GET requests. Returns HTML.\n",
    "    \"\"\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "    # Request the HTML from EconLog and parse the content.\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    html = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16982aff",
   "metadata": {
    "cell_id": "00003-1c995efa-8b49-497d-91d4-82f943f90b6d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1626196754973,
    "source_hash": "e48c1a92",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def request_containers(author, year):\n",
    "    \"\"\"\n",
    "    Download the HTML containers used to store the article's metadata for a given year.\n",
    "    Returns a list where each item is an article's HTML container.\n",
    "    \"\"\"\n",
    "\n",
    "    # Request the authors article's posted in the defined year.\n",
    "    url = 'https://www.econlib.org/author/{}/'.format(author)\n",
    "    html = make_request(url=url, params={'selected_year': year})\n",
    "\n",
    "    # Compile a complete list of posts for the year.\n",
    "    containers = html.find_all('div', {'class': 'min-card-posts-container'})\n",
    "\n",
    "    return containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f1550",
   "metadata": {
    "cell_id": "00007-604e4269-1e51-4950-bd99-a2b40962a172",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1626196754974,
    "source_hash": "23b47baa"
   },
   "outputs": [],
   "source": [
    "def request_article(url):\n",
    "    \"\"\"\n",
    "    For each article, request the content, returning the paragraph tags. Returns HTML.\n",
    "    \"\"\"\n",
    "    html = make_request(url=url)\n",
    "\n",
    "    # Post content is a list of paragraphs <p> tags.\n",
    "    article_content = html.find('div', attrs={\"class\": \"post-content\"}).find_all('p')\n",
    "\n",
    "    try:\n",
    "        article_label = html.find('div', attrs={\"class\": \"article-label\"}).text.strip()\n",
    "    except:\n",
    "        article_label = ''\n",
    "\n",
    "    return article_content, article_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93e1bd",
   "metadata": {
    "cell_id": "00002-3e6ff83f-6fa2-42fd-bc8e-e67fb6614a03",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1626196754975,
    "source_hash": "30e7b177",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_authors():\n",
    "    \"\"\"\n",
    "    Extracts all of the authors from the EconLog website. Returns a dictionary with the authors name (First, Last)\n",
    "    and their name tag in the websites HTML code.\n",
    "    \"\"\"\n",
    "    author_list = dict()\n",
    "\n",
    "    url = 'https://www.econlib.org/econlog-author'\n",
    "    html = make_request(url=url)    \n",
    "\n",
    "    # For each author, add the authors name (Last, First) and the author's user name.\n",
    "    for author in html.find_all('div', {'class':'title-cell'}):\n",
    "        author_list[author.find('a').text] = author.find('a').get('href').split('#')[1]\n",
    "\n",
    "    return author_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea0143",
   "metadata": {
    "cell_id": "00003-0e995f25-5d7a-4a7a-a1f1-e325fcdf3124",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1626196754982,
    "source_hash": "a2d376b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_years(author):\n",
    "    \"\"\"\n",
    "    Extract all of the years an author published an article. Returns a list of the years formatted as integers.\n",
    "    \"\"\"\n",
    "    years = []\n",
    "\n",
    "    url = 'https://www.econlib.org/author/{}'.format(author)\n",
    "    html = make_request(url=url)\n",
    "\n",
    "    for year in html.find_all('div', {'class':\"dropdown-menu dropdown-menu-right\"})[0].find_all('a'):\n",
    "        years.append(int(year.text))\n",
    "\n",
    "    return years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f63f0",
   "metadata": {
    "cell_id": "00003-7f6f079d-3d50-4085-bd29-d30c7e338df7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1626196755004,
    "source_hash": "d97514a"
   },
   "outputs": [],
   "source": [
    "def extract_metadata(container):\n",
    "    \"\"\"\n",
    "    For each article container, extract the metadata. Each container has the articles URL, title and date posted.\n",
    "    Returns a dictionary where each item is the articlces URL, title and date posted.\n",
    "\n",
    "    pd.to_datetime(container.find('span', {'class':'min-card-date'}).text, format=\"%b %d %Y\")\n",
    "    datetime.strptime(container.find('span', {'class':'min-card-date'}).text, '%b %d %Y')\n",
    "    \"\"\"\n",
    "    metadata = dict()\n",
    "\n",
    "    # For each post, extract the metadata: title, date, and url.\n",
    "    metadata['url'] = container.find('a').get('href')\n",
    "    metadata['title'] = container.find('a').text\n",
    "    metadata['date'] = datetime.strptime(container.find('span', {'class':'min-card-date'}).text, '%b %d %Y').strftime(\"%m/%d/%Y\")\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a79a9",
   "metadata": {
    "cell_id": "00008-d81e7f2e-73b7-4d2c-9fcb-5dd36c4138eb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1626196755005,
    "source_hash": "e6b2744"
   },
   "outputs": [],
   "source": [
    "def extract_urls(article):\n",
    "    \"\"\"\n",
    "    Extract the URLs embedded in article text, defined by 'p' tags. Returns a list of URLs.\n",
    "    \"\"\"\n",
    "    embedded_urls = set()\n",
    "\n",
    "    for p_tag in article:\n",
    "        urls = p_tag.find_all('a')\n",
    "\n",
    "        for url in urls:\n",
    "            embedded_urls.add(url.get('href'))\n",
    "\n",
    "    return embedded_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9e836",
   "metadata": {
    "cell_id": "00009-fee7722f-34b1-45a7-b4ee-f7cc63daedb8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1626196755005,
    "source_hash": "ab9bb0bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_text(article):\n",
    "    \"\"\"\n",
    "    Extract the article's text from the 'p' tags. Return a document (string).\n",
    "    \"\"\"\n",
    "    text = []\n",
    "\n",
    "    for p_tag in content:\n",
    "        text.append(p_tag.text)\n",
    "\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4316c",
   "metadata": {
    "cell_id": "00010-c48b1be4-8eae-46c7-825e-2b66c37ed162",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1626196755009,
    "source_hash": "19020a05",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_words(document):\n",
    "    \"\"\"\n",
    "    Count the number of words in\n",
    "    \"\"\"\n",
    "    document = document.replace(\"'\",'')\n",
    "    document = document.lower()\n",
    "    document = document.split()\n",
    "\n",
    "    word_list = Counter(document).most_common()\n",
    "    counts = [count for word, count in word_list]\n",
    "    word_count = np.sum(counts)\n",
    "\n",
    "    return word_count, word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b72098",
   "metadata": {
    "cell_id": "00005-b7d609d6-838c-4307-9f4a-f4ff0f4b47c0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Scape EconLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c32b68",
   "metadata": {
    "cell_id": "00002-0f95ec6d-561d-4764-849c-45ac07340eb5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 559,
    "execution_start": 1626196755014,
    "source_hash": "61e76f5a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find all of the authors who've published on EconLog. Returns a dictionary of the author and their\n",
    "# HTML user-name as {key:value}.\n",
    "published_authors = extract_authors()\n",
    "\n",
    "# Get the HTML user-name for Bryan Caplan.\n",
    "author = published_authors['Caplan, Bryan']\n",
    "\n",
    "# Using the user-name, extract all of the years the author published at least one article.\n",
    "published_years = extract_years(author=author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8a7cb",
   "metadata": {
    "cell_id": "00004-135a452c-6f81-49bd-a02a-b6e275a7056d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6058,
    "execution_start": 1626196755580,
    "source_hash": "f6f8734"
   },
   "outputs": [],
   "source": [
    "# In each year, request the HTML containers for the articles published in that year.\n",
    "# Each HTML container has the article's title, author, date, and the articles URL.\n",
    "article_metadata = dict()\n",
    "\n",
    "for year in published_years:\n",
    "    container_metadata = []\n",
    "\n",
    "    html_containers = request_containers(author=author, year=year)\n",
    "\n",
    "    for container in html_containers:\n",
    "        container_metadata.append(extract_metadata(container=container))\n",
    "\n",
    "    article_metadata[year] = container_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbebf99",
   "metadata": {
    "cell_id": "00010-8d33aa5c-dd0f-40f0-94b3-9f9ce24b715a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1453055,
    "execution_start": 1626196761642,
    "source_hash": "fba7716d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n",
      "2020\n",
      "2019\n",
      "2018\n",
      "2017\n",
      "2016\n",
      "2015\n",
      "2014\n",
      "2013\n",
      "2012\n",
      "2011\n",
      "2010\n",
      "2009\n",
      "2008\n",
      "2007\n",
      "2006\n",
      "2005\n"
     ]
    }
   ],
   "source": [
    "for year, articles in article_metadata.items():\n",
    "    print(year)\n",
    "    for index, article in enumerate(articles):\n",
    "        # Request the article content, returning tuple: (a list of HTML 'p' tags, the articles label).\n",
    "        content, label = request_article(url=article['url'])\n",
    "\n",
    "        # Extract embedded URLS.\n",
    "        embedded_urls = extract_urls(article=content)\n",
    "\n",
    "        # Extract article text.\n",
    "        text = extract_text(article=content)\n",
    "\n",
    "        # Calculate word count and extract word list.\n",
    "        word_count, word_list = count_words(document=text)\n",
    "\n",
    "        # Add features to the metadata dictionary.\n",
    "        article_metadata[year][index]['label'] = label\n",
    "        article_metadata[year][index]['word_count'] = word_count\n",
    "        article_metadata[year][index]['num_embedded_urls'] = len(embedded_urls)\n",
    "        article_metadata[year][index]['word_list'] = word_list\n",
    "        article_metadata[year][index]['embedded_urls'] = embedded_urls\n",
    "        article_metadata[year][index]['document'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd50ca8",
   "metadata": {
    "cell_id": "00014-49efd088-31fe-474f-9d63-2970d9a85d4b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 877,
    "execution_start": 1626199409365,
    "source_hash": "6d7f816",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export article content.\n",
    "\n",
    "# Note on JSON: JSON to forces str, but it human readable. Pass the \"default=str\" option\n",
    "# to avoid issues with JSON serializing datetime objects.\n",
    "# with open('article_content.json', 'w') as f:\n",
    "#     json.dump(article_metadata, f)#, default=str)\n",
    "\n",
    "# Note on Pickle: Maintains datatypes, although BS4 causes issues. All BS4 objects have been removed in this\n",
    "# iteration of the program.\n",
    "with open('../data/article_content.pkl', 'wb') as f:\n",
    "    pickle.dump(article_metadata, f)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "bb55d8f9-49f0-4f7d-9aa3-0ef4aee8612c",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
